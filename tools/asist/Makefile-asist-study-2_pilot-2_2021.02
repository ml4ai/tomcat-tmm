# This Makefile is pulled from laplace along with all the files
# needed for the study-2_pilot-2_2021.02 responsible. This is done by the
# targets in the Makefile-asist in the root of this project's directory. This
# file is responsible for
# 1. Pulling messages from the GCS and convert
# 2. Converting messages to an appropriate matrix format
# 3. Training a model using the converted messages
# 4. Saving (locally) the trained parameters for future usage
# 5. Uploading the trained parameters to Laplace (requires explicitly target
# execution)
# 6. Starting an online agent with a model with pre-trained params (requires
# explicitly target execution)

SERVER = laplace
ASIST_SERVER_DIR = /data/asist

# The name of the Google Cloud Source folder where the ASIST HSR data resides.
STUDY_ID = study-2_pilot-2_2021.02

# Binaries required for the ASIST evaluation analyses
BUILD_DIR = ../../../build

# Path to the files containing the maps definition
MAP_DIR = map
MAP_PATH = $(MAP_DIR)/Saturn_1.0_sm_v1.0.json

# Path to the file containing the model definition
MODEL_PATH = ../../../models/tomcat-v04.json

# Original data from the message bus to be used for training
MSG_DIR = messages
SPLIT_MSG_DIR = split_messages
TRAIN_MSG_DIR = $(SPLIT_MSG_DIR)/train

# File with the trial numbers to use for training
TRAIN_TRIALS_FILE = $(SPLIT_MSG_DIR)/train_list.txt

# Directory where converted data will reside
SAMPLES_DIR = samples
TRAIN_SAMPLES_DIR = $(SAMPLES_DIR)/train

# Directory where the trained parameters will be saved
PARAMS_DIR = params

# For estimation
INFERENCE_PATH = inference.json
BROKER_PATH = broker.json

# Phony targets
.PHONY: all
.PHONY: build
.PHONY: sync
.PHONY: split
.PHONY: map
.PHONY: convert
.PHONY: train
.PHONY: upload
.PHONY: start

all: build sync split map convert train

# Builds the system so that the model is retrained if there's a new version of
# the executable available and create the necessary folders for the files
# generated by this script.
build:
	@cd $(BUILD_DIR) && make -j convert
	@cd $(BUILD_DIR) && make -j train

# Synchronize message folder with the GSC
sync:
	@GCS_DIR=$(STUDY_ID) DATA_DIR=$(MSG_DIR) ../../../tools/asist/sync_asist_data

split: $(TRAIN_MSG_DIR)

# Creates symbolic links for the message files in the folder split_messages
# according to the trial numbers defined for training.
$(TRAIN_MSG_DIR): ../../../tools/asist/split_asist_data $(TRAIN_TRIALS_FILE)
	@echo "Reserving training messages..."
	@ORIGINAL_MSG_DIR=$(MSG_DIR) TRIALS_FILE=$(TRAIN_TRIALS_FILE) \
	TARGET_MSG_DIR=$@ ./$<

# Downloads the map used in this study from the collections of all ASIST
# maps in Laplace
map: $(MAP_PATH)

$(MAP_PATH):
	@echo "Downloading map..."
	@mkdir -p $(@D)
	@scp $(SERVER):$(ASIST_SERVER_DIR)/maps/$(@F) $(MAP_PATH)

# Parses messages from the test bed and converts them to matrices of
# observations. One matrix for each observable node in the model. We always
# try to convert, if there's nothing to convert, the program will handle that.
convert: $(TRAIN_SAMPLES_DIR)

$(TRAIN_SAMPLES_DIR):
	@echo "Converting training data..."
	@./$(BUILD_DIR)/bin/convert --map_json $(MAP_PATH) \
		--messages_dir $(TRAIN_MSG_DIR) --data_dir $(TRAIN_SAMPLES_DIR) \
		--seconds 900 --step_size 1 --multiplayer

# The model only needs to be retrained if the executable changed, or if any of
# the files in $(TRAIN_SAMPLES_DIR) changed.
train: $(PARAMS_DIR)

# We insert and remove a dummy file to change the modification date of the
# directory
$(PARAMS_DIR): $(BUILD_DIR)/bin/train $(TRAIN_SAMPLES_DIR)/conversion_log.json
	@echo "Training model..."
	@./$< --model_json $(MODEL_PATH) --data_dir $(TRAIN_SAMPLES_DIR) \
	    --params_dir $@ --T 900 --burn_in 50 --samples 100 --jobs 4
	@touch $@/dummy.txt
	@rm $@/dummy.txt

upload:
	@echo "Compressing parameters..."
	@tar --exclude partials/ --exclude '.DS_Store' -zcf params.tar.gz params
	@echo "Uploading parameters to Laplace..."
	@scp params.tar.gz $(SERVER):$(ASIST_SERVER_DIR)/$(STUDY_ID)
	@rm params.tar.gz

start:
	@cd $(BUILD_DIR) && make -j start_agent
	@./$(BUILD_DIR)/bin/start_agent --agent_id "ToMCAT" \
	--model_json $(MODEL_PATH) --params_dir $(PARAMS_DIR) \
	--broker_json $(BROKER_PATH) --map_json $(MAP_PATH) --seconds 900 \
	--step_size 1 --inference_json $(INFERENCE_PATH) \
 	--burn_in 1 --samples 100 --jobs 4


